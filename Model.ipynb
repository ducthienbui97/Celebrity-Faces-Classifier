{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras import optimizers \n",
    "from keras.callbacks import ModelCheckpoint, History, Callback\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58852 images belonging to 256 classes.\n",
      "Found 14718 images belonging to 256 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validate'\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(30, 30),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(30, 30),\n",
    "    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 29, 29, 64)        832       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 28, 28, 128)       32896     \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 27, 27, 256)       131328    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 26, 26, 256)       262400    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       524800    \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 11, 11, 512)       1049088   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 4,362,432\n",
      "Trainable params: 4,362,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(size):\n",
    "    model = Sequential()\n",
    "    init = 'he_normal'\n",
    "    model.add(Conv2D(64, (2, 2), activation = 'relu', name = 'block1_conv1', \n",
    "                            kernel_initializer = init, input_shape = (size, size, 3)))\n",
    "#     model.add(Conv2D(64, (2, 2), activation = 'relu', name = 'block1_conv2', kernel_initializer = init))\n",
    "    model.add(MaxPooling2D((1, 1), name = 'block1_pool'))\n",
    "\n",
    "    model.add(Conv2D(128, (2, 2), activation = 'relu', name = 'block2_conv1', kernel_initializer = init))\n",
    "#     model.add(Conv2D(128, (2, 2), activation = 'relu', name = 'block2_conv2', kernel_initializer = init))\n",
    "    model.add(MaxPooling2D((1, 1), name = 'block2_pool'))\n",
    "\n",
    "    model.add(Conv2D(256, (2, 2), activation = 'relu', name = 'block3_conv1', kernel_initializer = init))\n",
    "    model.add(Conv2D(256, (2, 2), activation = 'relu', name = 'block3_conv2', kernel_initializer = init))\n",
    "    model.add(MaxPooling2D((2, 2), name = 'block3_pool'))\n",
    "\n",
    "    model.add(Conv2D(512, (2, 2), activation = 'relu', name = 'block4_conv1', kernel_initializer = init))\n",
    "    model.add(Conv2D(512, (2, 2), activation = 'relu', name = 'block4_conv2', kernel_initializer = init))\n",
    "    model.add(MaxPooling2D((2, 2), name = 'block4_pool'))\n",
    "    \n",
    "    model.add(Conv2D(512, (2, 2), activation = 'relu', name = 'block5_conv1', kernel_initializer=init))\n",
    "    model.add(Conv2D(512, (2, 2), activation = 'relu', name = 'block5_conv2', kernel_initializer=init))\n",
    "    model.add(MaxPooling2D((2, 2), name = 'block5_pool'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = 'relu', kernel_initializer = init, name = 'fc1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation = 'relu', kernel_initializer = init, name = 'fc2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation = 'softmax', name = 'predictions'))\n",
    "    \n",
    "    optim = Adam(lr = 0.0005)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model(size=30)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 363s - loss: 5.3796 - acc: 0.0215 - val_loss: 5.3333 - val_acc: 0.0249\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 356s - loss: 5.3414 - acc: 0.0231 - val_loss: 5.3178 - val_acc: 0.0228\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 355s - loss: 5.2164 - acc: 0.0300 - val_loss: 5.0929 - val_acc: 0.0440\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 355s - loss: 4.9278 - acc: 0.0447 - val_loss: 4.6569 - val_acc: 0.0579\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 354s - loss: 4.7608 - acc: 0.0507 - val_loss: 4.5058 - val_acc: 0.0701\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 354s - loss: 4.6381 - acc: 0.0602 - val_loss: 4.4142 - val_acc: 0.0696\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 355s - loss: 4.5439 - acc: 0.0680 - val_loss: 4.3153 - val_acc: 0.0896\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 355s - loss: 4.4573 - acc: 0.0760 - val_loss: 4.2214 - val_acc: 0.1065\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 355s - loss: 4.3932 - acc: 0.0846 - val_loss: 4.2014 - val_acc: 0.1057\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 354s - loss: 4.3233 - acc: 0.0917 - val_loss: 4.0454 - val_acc: 0.1262\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 355s - loss: 4.2831 - acc: 0.0985 - val_loss: 4.0370 - val_acc: 0.1321\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 356s - loss: 4.2259 - acc: 0.1061 - val_loss: 3.9648 - val_acc: 0.1409\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 358s - loss: 4.1797 - acc: 0.1116 - val_loss: 3.9155 - val_acc: 0.1503\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 357s - loss: 4.1400 - acc: 0.1181 - val_loss: 3.8085 - val_acc: 0.1688\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 357s - loss: 4.0674 - acc: 0.1268 - val_loss: 3.7978 - val_acc: 0.1697\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 358s - loss: 4.0485 - acc: 0.1341 - val_loss: 3.6600 - val_acc: 0.1886\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 357s - loss: 4.0031 - acc: 0.1407 - val_loss: 3.7190 - val_acc: 0.1930\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 357s - loss: 3.9797 - acc: 0.1434 - val_loss: 3.6971 - val_acc: 0.1871\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 357s - loss: 3.9360 - acc: 0.1519 - val_loss: 3.6184 - val_acc: 0.2076\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 357s - loss: 3.9240 - acc: 0.1525 - val_loss: 3.5724 - val_acc: 0.2089\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 357s - loss: 3.8806 - acc: 0.1626 - val_loss: 3.4760 - val_acc: 0.2216\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 357s - loss: 3.8771 - acc: 0.1657 - val_loss: 3.4725 - val_acc: 0.2266\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 358s - loss: 3.8165 - acc: 0.1709 - val_loss: 3.4243 - val_acc: 0.2393\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 357s - loss: 3.8145 - acc: 0.1748 - val_loss: 3.5218 - val_acc: 0.2231\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 355s - loss: 3.7809 - acc: 0.1804 - val_loss: 3.4744 - val_acc: 0.2299\n",
      "Epoch 26/50\n",
      " 980/2000 [=============>................] - ETA: 171s - loss: 3.7787 - acc: 0.1819"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs= epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
