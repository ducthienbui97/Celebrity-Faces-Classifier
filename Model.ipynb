{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model,Sequential,load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 129658 images belonging to 88 classes.\n",
      "Found 25448 images belonging to 88 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validate'\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "image_size = 30\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   rotation_range=30)\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed = 1997)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    seed = 1997)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 29, 29, 32)        416       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 28, 28, 32)        4128      \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 13, 13, 64)        8256      \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 12, 12, 128)       32896     \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 5, 5, 256)         131328    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 4, 4, 512)         524800    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 88)                22616     \n",
      "=================================================================\n",
      "Total params: 1,904,856\n",
      "Trainable params: 1,904,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(size):\n",
    "    model = Sequential()\n",
    "    init = 'he_normal'\n",
    "    model.add(Conv2D(32, (2, 2), activation = 'relu', name = 'block1_conv1', \n",
    "                            kernel_initializer = init, input_shape = (size, size, 3)))\n",
    "    model.add(Conv2D(32, (2, 2), activation = 'relu', name = 'block1_conv2', kernel_initializer = init))\n",
    "    model.add(MaxPooling2D((2, 2), name = 'block1_pool'))\n",
    "\n",
    "    model.add(Conv2D(64, (2, 2), activation = 'relu', name = 'block2_conv1', kernel_initializer = init))\n",
    "    model.add(Conv2D(128, (2, 2), activation = 'relu', name = 'block2_conv2', kernel_initializer = init))\n",
    "    model.add(MaxPooling2D((2, 2), name = 'block2_pool'))\n",
    "\n",
    "    model.add(Conv2D(256, (2, 2), activation = 'relu', name = 'block3_conv1', kernel_initializer = init))\n",
    "    model.add(Conv2D(512, (2, 2), activation = 'relu', name = 'block3_conv2', kernel_initializer = init))\n",
    "    model.add(MaxPooling2D((2, 2), name = 'block3_pool'))\n",
    "    \n",
    "#     model.add(Conv2D(512, (2, 2), activation = 'relu', name = 'block4_conv1', kernel_initializer=init))\n",
    "#     model.add(Conv2D(512, (2, 2), activation = 'relu', name = 'block4_conv2', kernel_initializer=init))\n",
    "#     model.add(MaxPooling2D((2, 2), name = 'block4_pool'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation = 'relu', kernel_initializer = init, name = 'fc1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation = 'relu', kernel_initializer = init, name = 'fc2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(88, activation = 'softmax', name = 'predictions'))\n",
    "    \n",
    "    optim = Adam(lr = 0.0005)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model(size = image_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 2337s - loss: 4.1840 - acc: 0.0411 - val_loss: 3.6917 - val_acc: 0.1012\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 353s - loss: 3.7305 - acc: 0.1046 - val_loss: 3.3579 - val_acc: 0.1699\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 333s - loss: 3.5060 - acc: 0.1464 - val_loss: 3.1061 - val_acc: 0.2228\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 333s - loss: 3.3645 - acc: 0.1763 - val_loss: 2.9393 - val_acc: 0.2668\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 332s - loss: 3.2635 - acc: 0.1987 - val_loss: 2.8567 - val_acc: 0.2904\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 333s - loss: 3.1792 - acc: 0.2168 - val_loss: 2.7338 - val_acc: 0.3206\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 334s - loss: 3.1191 - acc: 0.2318 - val_loss: 2.7028 - val_acc: 0.3197\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 334s - loss: 3.0628 - acc: 0.2455 - val_loss: 2.6201 - val_acc: 0.3552\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 334s - loss: 3.0147 - acc: 0.2554 - val_loss: 2.5873 - val_acc: 0.3570\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 337s - loss: 2.9700 - acc: 0.2676 - val_loss: 2.5239 - val_acc: 0.3762\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 336s - loss: 2.9400 - acc: 0.2754 - val_loss: 2.4833 - val_acc: 0.3854\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 331s - loss: 2.9087 - acc: 0.2821 - val_loss: 2.4585 - val_acc: 0.3911\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 328s - loss: 2.8819 - acc: 0.2904 - val_loss: 2.5228 - val_acc: 0.3846\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 328s - loss: 2.8535 - acc: 0.2985 - val_loss: 2.3781 - val_acc: 0.4111\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 328s - loss: 2.8342 - acc: 0.3036 - val_loss: 2.3658 - val_acc: 0.4210\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 336s - loss: 2.8179 - acc: 0.3063 - val_loss: 2.3056 - val_acc: 0.4324\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 347s - loss: 2.7938 - acc: 0.3133 - val_loss: 2.3471 - val_acc: 0.4233\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 342s - loss: 2.7777 - acc: 0.3160 - val_loss: 2.2986 - val_acc: 0.4331\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 348s - loss: 2.7613 - acc: 0.3206 - val_loss: 2.2809 - val_acc: 0.4392\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 346s - loss: 2.7485 - acc: 0.3251 - val_loss: 2.2624 - val_acc: 0.4424\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 340s - loss: 2.7371 - acc: 0.3276 - val_loss: 2.2476 - val_acc: 0.4447\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 343s - loss: 2.7233 - acc: 0.3304 - val_loss: 2.2576 - val_acc: 0.4449\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 344s - loss: 2.7092 - acc: 0.3348 - val_loss: 2.2409 - val_acc: 0.4608\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 344s - loss: 2.7056 - acc: 0.3375 - val_loss: 2.2319 - val_acc: 0.4544\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 341s - loss: 2.6883 - acc: 0.3410 - val_loss: 2.2336 - val_acc: 0.4553\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 347s - loss: 2.6826 - acc: 0.3440 - val_loss: 2.2309 - val_acc: 0.4540\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 353s - loss: 2.6682 - acc: 0.3458 - val_loss: 2.2192 - val_acc: 0.4602\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 353s - loss: 2.6656 - acc: 0.3470 - val_loss: 2.1966 - val_acc: 0.4624\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 352s - loss: 2.6591 - acc: 0.3505 - val_loss: 2.2116 - val_acc: 0.4594\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 353s - loss: 2.6429 - acc: 0.3531 - val_loss: 2.1207 - val_acc: 0.4830\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 353s - loss: 2.6400 - acc: 0.3535 - val_loss: 2.1282 - val_acc: 0.4776\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 354s - loss: 2.6257 - acc: 0.3574 - val_loss: 2.2064 - val_acc: 0.4639\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 354s - loss: 2.6297 - acc: 0.3580 - val_loss: 2.1644 - val_acc: 0.4690\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 354s - loss: 2.6088 - acc: 0.3630 - val_loss: 2.1448 - val_acc: 0.4795\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 355s - loss: 2.6095 - acc: 0.3627 - val_loss: 2.1080 - val_acc: 0.4866\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 354s - loss: 2.6104 - acc: 0.3649 - val_loss: 2.1220 - val_acc: 0.4823\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 354s - loss: 2.5961 - acc: 0.3655 - val_loss: 2.1206 - val_acc: 0.4900\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 342s - loss: 2.5971 - acc: 0.3660 - val_loss: 2.1281 - val_acc: 0.4848\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 338s - loss: 2.5928 - acc: 0.3678 - val_loss: 2.0956 - val_acc: 0.4960\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 343s - loss: 2.5803 - acc: 0.3717 - val_loss: 2.0862 - val_acc: 0.4917\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 343s - loss: 2.5785 - acc: 0.3725 - val_loss: 2.0724 - val_acc: 0.4904\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 346s - loss: 2.5828 - acc: 0.3716 - val_loss: 2.0532 - val_acc: 0.5005\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 343s - loss: 2.5660 - acc: 0.3747 - val_loss: 2.1110 - val_acc: 0.4874\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 342s - loss: 2.5720 - acc: 0.3734 - val_loss: 2.0469 - val_acc: 0.5039\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 341s - loss: 2.5673 - acc: 0.3761 - val_loss: 2.0816 - val_acc: 0.4991\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.5634 - acc: 0.3774 - val_loss: 2.1492 - val_acc: 0.4768\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 338s - loss: 2.5551 - acc: 0.3787 - val_loss: 2.1226 - val_acc: 0.4901\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 340s - loss: 2.5575 - acc: 0.3765 - val_loss: 2.0195 - val_acc: 0.5107\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 340s - loss: 2.5444 - acc: 0.3823 - val_loss: 2.0320 - val_acc: 0.5088\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 340s - loss: 2.5454 - acc: 0.3820 - val_loss: 2.0363 - val_acc: 0.5093\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 348s - loss: 2.5464 - acc: 0.3846 - val_loss: 2.1120 - val_acc: 0.4886\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 349s - loss: 2.5426 - acc: 0.3841 - val_loss: 2.0265 - val_acc: 0.5107\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 347s - loss: 2.5405 - acc: 0.3845 - val_loss: 1.9974 - val_acc: 0.5186\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 345s - loss: 2.5297 - acc: 0.3872 - val_loss: 2.0485 - val_acc: 0.4999\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 342s - loss: 2.5273 - acc: 0.3865 - val_loss: 2.0290 - val_acc: 0.5106\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 343s - loss: 2.5306 - acc: 0.3898 - val_loss: 2.0381 - val_acc: 0.5089\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 342s - loss: 2.5243 - acc: 0.3886 - val_loss: 1.9934 - val_acc: 0.5206\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 350s - loss: 2.5240 - acc: 0.3895 - val_loss: 2.0200 - val_acc: 0.5114\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 348s - loss: 2.5219 - acc: 0.3894 - val_loss: 2.0175 - val_acc: 0.5154\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 347s - loss: 2.5222 - acc: 0.3908 - val_loss: 2.0602 - val_acc: 0.5057\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 351s - loss: 2.5110 - acc: 0.3937 - val_loss: 2.0124 - val_acc: 0.5190\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 778s - loss: 2.5159 - acc: 0.3938 - val_loss: 2.0246 - val_acc: 0.5159\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 341s - loss: 2.5206 - acc: 0.3916 - val_loss: 2.0041 - val_acc: 0.5218\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 339s - loss: 2.5083 - acc: 0.3946 - val_loss: 1.9992 - val_acc: 0.5250\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.5087 - acc: 0.3957 - val_loss: 1.9993 - val_acc: 0.5162\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.5086 - acc: 0.3950 - val_loss: 2.0149 - val_acc: 0.5198\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.5029 - acc: 0.3955 - val_loss: 2.0166 - val_acc: 0.5141\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 340s - loss: 2.5003 - acc: 0.3979 - val_loss: 2.0503 - val_acc: 0.5064\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.5023 - acc: 0.3965 - val_loss: 2.0440 - val_acc: 0.5057\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4996 - acc: 0.3990 - val_loss: 1.9771 - val_acc: 0.5243\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.5130 - acc: 0.3964 - val_loss: 2.0008 - val_acc: 0.5192\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 340s - loss: 2.4943 - acc: 0.3987 - val_loss: 1.9182 - val_acc: 0.5398\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4997 - acc: 0.3999 - val_loss: 2.0424 - val_acc: 0.5069\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4900 - acc: 0.3998 - val_loss: 1.9713 - val_acc: 0.5305\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4932 - acc: 0.3995 - val_loss: 2.0213 - val_acc: 0.5158\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4939 - acc: 0.4015 - val_loss: 1.9721 - val_acc: 0.5265\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4946 - acc: 0.4004 - val_loss: 1.9311 - val_acc: 0.5416\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4886 - acc: 0.4027 - val_loss: 2.0591 - val_acc: 0.5050\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4877 - acc: 0.4033 - val_loss: 1.9941 - val_acc: 0.5202\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4898 - acc: 0.4019 - val_loss: 2.0077 - val_acc: 0.5168\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 340s - loss: 2.4861 - acc: 0.4048 - val_loss: 1.9760 - val_acc: 0.5280\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4844 - acc: 0.4034 - val_loss: 1.9362 - val_acc: 0.5384\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 340s - loss: 2.4843 - acc: 0.4029 - val_loss: 1.9956 - val_acc: 0.5227\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4877 - acc: 0.4038 - val_loss: 2.0232 - val_acc: 0.5165\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4781 - acc: 0.4064 - val_loss: 2.0031 - val_acc: 0.5216\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 340s - loss: 2.4827 - acc: 0.4044 - val_loss: 2.0104 - val_acc: 0.5216\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 340s - loss: 2.4877 - acc: 0.4045 - val_loss: 1.9653 - val_acc: 0.5315\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 341s - loss: 2.4782 - acc: 0.4060 - val_loss: 1.9723 - val_acc: 0.5233\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 340s - loss: 2.4743 - acc: 0.4067 - val_loss: 2.0435 - val_acc: 0.5157\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 341s - loss: 2.4763 - acc: 0.4069 - val_loss: 1.9960 - val_acc: 0.5263\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4834 - acc: 0.4043 - val_loss: 1.9751 - val_acc: 0.5266\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4694 - acc: 0.4101 - val_loss: 1.9592 - val_acc: 0.5298\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4683 - acc: 0.4078 - val_loss: 1.9835 - val_acc: 0.5268\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4744 - acc: 0.4087 - val_loss: 1.9959 - val_acc: 0.5242\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4807 - acc: 0.4072 - val_loss: 2.0080 - val_acc: 0.5228\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4855 - acc: 0.4060 - val_loss: 1.9645 - val_acc: 0.5298\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4714 - acc: 0.4088 - val_loss: 1.9802 - val_acc: 0.5320\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 340s - loss: 2.4773 - acc: 0.4079 - val_loss: 1.9854 - val_acc: 0.5281\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4704 - acc: 0.4109 - val_loss: 1.9909 - val_acc: 0.5309\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 339s - loss: 2.4677 - acc: 0.4098 - val_loss: 2.0102 - val_acc: 0.5213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e5a8821898>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = 8000,\n",
    "        epochs = epochs,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('model.h5') "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
