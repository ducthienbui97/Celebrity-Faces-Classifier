{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model,Sequential,load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58852 images belonging to 256 classes.\n",
      "Found 14718 images belonging to 256 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validate'\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "image_size = 30\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 29, 29, 32)        416       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 28, 28, 64)        8256      \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 13, 13, 128)       32896     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 12, 12, 256)       131328    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 5, 5, 512)         524800    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 4, 4, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 256)               131328    \n",
      "=================================================================\n",
      "Total params: 4,501,088\n",
      "Trainable params: 4,501,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(size):\n",
    "    model = Sequential()\n",
    "    init = 'he_normal'\n",
    "    model.add(Conv2D(32, (2, 2), activation = 'relu', name = 'block1_conv1', \n",
    "                            kernel_initializer = init, input_shape = (size, size, 3)))\n",
    "    model.add(Conv2D(64, (2, 2), activation = 'relu', name = 'block1_conv2', kernel_initializer = init))\n",
    "    model.add(MaxPooling2D((2, 2), name = 'block1_pool'))\n",
    "\n",
    "    model.add(Conv2D(128, (2, 2), activation = 'relu', name = 'block2_conv1', kernel_initializer = init))\n",
    "    model.add(Conv2D(256, (2, 2), activation = 'relu', name = 'block2_conv2', kernel_initializer = init))\n",
    "    model.add(MaxPooling2D((2, 2), name = 'block2_pool'))\n",
    "\n",
    "    model.add(Conv2D(512, (2, 2), activation = 'relu', name = 'block3_conv1', kernel_initializer = init))\n",
    "    model.add(Conv2D(512, (2, 2), activation = 'relu', name = 'block3_conv2', kernel_initializer = init))\n",
    "    model.add(MaxPooling2D((2, 2), name = 'block3_pool'))\n",
    "    \n",
    "#     model.add(Conv2D(512, (2, 2), activation = 'relu', name = 'block4_conv1', kernel_initializer=init))\n",
    "#     model.add(Conv2D(512, (2, 2), activation = 'relu', name = 'block4_conv2', kernel_initializer=init))\n",
    "#     model.add(MaxPooling2D((2, 2), name = 'block4_pool'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation = 'relu', kernel_initializer = init, name = 'fc1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation = 'relu', kernel_initializer = init, name = 'fc2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation = 'softmax', name = 'predictions'))\n",
    "    \n",
    "    optim = Adam(lr = 0.0005)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model(size = image_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1600/1600 [==============================] - 121s - loss: 5.3726 - acc: 0.0216 - val_loss: 5.3304 - val_acc: 0.0267\n",
      "Epoch 2/200\n",
      "1600/1600 [==============================] - 118s - loss: 5.2642 - acc: 0.0299 - val_loss: 5.0813 - val_acc: 0.0387\n",
      "Epoch 3/200\n",
      "1600/1600 [==============================] - 118s - loss: 5.0077 - acc: 0.0425 - val_loss: 4.7586 - val_acc: 0.0563\n",
      "Epoch 4/200\n",
      "1600/1600 [==============================] - 118s - loss: 4.7805 - acc: 0.0546 - val_loss: 4.5474 - val_acc: 0.0739\n",
      "Epoch 5/200\n",
      "1600/1600 [==============================] - 118s - loss: 4.5937 - acc: 0.0681 - val_loss: 4.3869 - val_acc: 0.0917\n",
      "Epoch 6/200\n",
      "1600/1600 [==============================] - 117s - loss: 4.4434 - acc: 0.0843 - val_loss: 4.1397 - val_acc: 0.1181\n",
      "Epoch 7/200\n",
      "1600/1600 [==============================] - 116s - loss: 4.3331 - acc: 0.0959 - val_loss: 4.0289 - val_acc: 0.1299\n",
      "Epoch 8/200\n",
      "1600/1600 [==============================] - 116s - loss: 4.2091 - acc: 0.1102 - val_loss: 3.9605 - val_acc: 0.1525\n",
      "Epoch 9/200\n",
      "1600/1600 [==============================] - 117s - loss: 4.1344 - acc: 0.1200 - val_loss: 3.8348 - val_acc: 0.1637\n",
      "Epoch 10/200\n",
      "1600/1600 [==============================] - 116s - loss: 4.0236 - acc: 0.1360 - val_loss: 3.7206 - val_acc: 0.1835\n",
      "Epoch 11/200\n",
      "1600/1600 [==============================] - 117s - loss: 3.9857 - acc: 0.1373 - val_loss: 3.6009 - val_acc: 0.2068\n",
      "Epoch 12/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.9091 - acc: 0.1552 - val_loss: 3.6108 - val_acc: 0.2012\n",
      "Epoch 13/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.8422 - acc: 0.1670 - val_loss: 3.5691 - val_acc: 0.2159\n",
      "Epoch 14/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.8095 - acc: 0.1715 - val_loss: 3.4157 - val_acc: 0.2435\n",
      "Epoch 15/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.7472 - acc: 0.1777 - val_loss: 3.4361 - val_acc: 0.2376\n",
      "Epoch 16/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.7233 - acc: 0.1892 - val_loss: 3.3584 - val_acc: 0.2522\n",
      "Epoch 17/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.6514 - acc: 0.1947 - val_loss: 3.3095 - val_acc: 0.2712\n",
      "Epoch 18/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.6416 - acc: 0.1996 - val_loss: 3.2848 - val_acc: 0.2757\n",
      "Epoch 19/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.5551 - acc: 0.2138 - val_loss: 3.2977 - val_acc: 0.2712\n",
      "Epoch 20/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.5558 - acc: 0.2121 - val_loss: 3.1279 - val_acc: 0.2980\n",
      "Epoch 21/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.5296 - acc: 0.2168 - val_loss: 3.0738 - val_acc: 0.3125\n",
      "Epoch 22/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.4837 - acc: 0.2270 - val_loss: 3.1145 - val_acc: 0.3129\n",
      "Epoch 23/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.4742 - acc: 0.2313 - val_loss: 3.0585 - val_acc: 0.3215\n",
      "Epoch 24/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.4296 - acc: 0.2373 - val_loss: 3.0503 - val_acc: 0.3199\n",
      "Epoch 25/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.4016 - acc: 0.2434 - val_loss: 3.0379 - val_acc: 0.3275\n",
      "Epoch 26/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.3678 - acc: 0.2495 - val_loss: 2.9858 - val_acc: 0.3226\n",
      "Epoch 27/200\n",
      "1600/1600 [==============================] - 117s - loss: 3.3675 - acc: 0.2518 - val_loss: 2.9071 - val_acc: 0.3463\n",
      "Epoch 28/200\n",
      "1600/1600 [==============================] - 117s - loss: 3.3410 - acc: 0.2590 - val_loss: 2.9273 - val_acc: 0.3485\n",
      "Epoch 29/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.3282 - acc: 0.2574 - val_loss: 2.9571 - val_acc: 0.3344\n",
      "Epoch 30/200\n",
      "1600/1600 [==============================] - 117s - loss: 3.3129 - acc: 0.2655 - val_loss: 2.8584 - val_acc: 0.3607\n",
      "Epoch 31/200\n",
      "1600/1600 [==============================] - 117s - loss: 3.2755 - acc: 0.2668 - val_loss: 2.8373 - val_acc: 0.3681\n",
      "Epoch 32/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.2748 - acc: 0.2710 - val_loss: 2.8151 - val_acc: 0.3656\n",
      "Epoch 33/200\n",
      "1600/1600 [==============================] - 115s - loss: 3.2613 - acc: 0.2759 - val_loss: 2.8751 - val_acc: 0.3571\n",
      "Epoch 34/200\n",
      "1600/1600 [==============================] - 118s - loss: 3.2384 - acc: 0.2785 - val_loss: 2.7980 - val_acc: 0.3689\n",
      "Epoch 35/200\n",
      "1600/1600 [==============================] - 117s - loss: 3.2260 - acc: 0.2800 - val_loss: 2.7553 - val_acc: 0.3739\n",
      "Epoch 36/200\n",
      "1600/1600 [==============================] - 117s - loss: 3.1992 - acc: 0.2855 - val_loss: 2.7917 - val_acc: 0.3690\n",
      "Epoch 37/200\n",
      "1600/1600 [==============================] - 117s - loss: 3.1981 - acc: 0.2829 - val_loss: 2.7144 - val_acc: 0.3809\n",
      "Epoch 38/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.1721 - acc: 0.2884 - val_loss: 2.7358 - val_acc: 0.3877\n",
      "Epoch 39/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.1924 - acc: 0.2909 - val_loss: 2.7682 - val_acc: 0.3871\n",
      "Epoch 40/200\n",
      "1600/1600 [==============================] - 117s - loss: 3.1481 - acc: 0.2956 - val_loss: 2.6596 - val_acc: 0.3972\n",
      "Epoch 41/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.1646 - acc: 0.2950 - val_loss: 2.7260 - val_acc: 0.3843\n",
      "Epoch 42/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.1117 - acc: 0.3013 - val_loss: 2.5851 - val_acc: 0.4165\n",
      "Epoch 43/200\n",
      "1600/1600 [==============================] - 115s - loss: 3.1346 - acc: 0.2963 - val_loss: 2.6538 - val_acc: 0.4042\n",
      "Epoch 44/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.1105 - acc: 0.3023 - val_loss: 2.6615 - val_acc: 0.4027\n",
      "Epoch 45/200\n",
      "1600/1600 [==============================] - 113s - loss: 3.1226 - acc: 0.3024 - val_loss: 2.6863 - val_acc: 0.4005\n",
      "Epoch 46/200\n",
      "1600/1600 [==============================] - 113s - loss: 3.1114 - acc: 0.3040 - val_loss: 2.6664 - val_acc: 0.4050\n",
      "Epoch 47/200\n",
      "1600/1600 [==============================] - 113s - loss: 3.0678 - acc: 0.3121 - val_loss: 2.6091 - val_acc: 0.4230\n",
      "Epoch 48/200\n",
      "1600/1600 [==============================] - 113s - loss: 3.0989 - acc: 0.3085 - val_loss: 2.6300 - val_acc: 0.4069\n",
      "Epoch 49/200\n",
      "1600/1600 [==============================] - 113s - loss: 3.0689 - acc: 0.3089 - val_loss: 2.6195 - val_acc: 0.4156\n",
      "Epoch 50/200\n",
      "1600/1600 [==============================] - 112s - loss: 3.0798 - acc: 0.3110 - val_loss: 2.5775 - val_acc: 0.4257\n",
      "Epoch 51/200\n",
      "1600/1600 [==============================] - 117s - loss: 3.0541 - acc: 0.3193 - val_loss: 2.5310 - val_acc: 0.4239\n",
      "Epoch 52/200\n",
      "1600/1600 [==============================] - 118s - loss: 3.0388 - acc: 0.3187 - val_loss: 2.5613 - val_acc: 0.4222\n",
      "Epoch 53/200\n",
      "1600/1600 [==============================] - 118s - loss: 3.0815 - acc: 0.3130 - val_loss: 2.5866 - val_acc: 0.4214\n",
      "Epoch 54/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.0161 - acc: 0.3229 - val_loss: 2.5911 - val_acc: 0.4166\n",
      "Epoch 55/200\n",
      "1600/1600 [==============================] - 118s - loss: 3.0344 - acc: 0.3251 - val_loss: 2.5251 - val_acc: 0.4404\n",
      "Epoch 56/200\n",
      "1600/1600 [==============================] - 119s - loss: 3.0081 - acc: 0.3248 - val_loss: 2.5766 - val_acc: 0.4242\n",
      "Epoch 57/200\n",
      "1600/1600 [==============================] - 117s - loss: 3.0017 - acc: 0.3281 - val_loss: 2.5009 - val_acc: 0.4349\n",
      "Epoch 58/200\n",
      "1600/1600 [==============================] - 117s - loss: 3.0261 - acc: 0.3252 - val_loss: 2.5297 - val_acc: 0.4360\n",
      "Epoch 59/200\n",
      "1600/1600 [==============================] - 117s - loss: 3.0043 - acc: 0.3272 - val_loss: 2.4953 - val_acc: 0.4451\n",
      "Epoch 60/200\n",
      "1600/1600 [==============================] - 116s - loss: 2.9863 - acc: 0.3304 - val_loss: 2.5417 - val_acc: 0.4354\n",
      "Epoch 61/200\n",
      "1600/1600 [==============================] - 116s - loss: 2.9964 - acc: 0.3312 - val_loss: 2.5061 - val_acc: 0.4411\n",
      "Epoch 62/200\n",
      "1600/1600 [==============================] - 116s - loss: 3.0047 - acc: 0.3300 - val_loss: 2.4906 - val_acc: 0.4436\n",
      "Epoch 63/200\n",
      "1600/1600 [==============================] - 116s - loss: 2.9622 - acc: 0.3386 - val_loss: 2.4324 - val_acc: 0.4637\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 117s - loss: 2.9860 - acc: 0.3345 - val_loss: 2.4828 - val_acc: 0.4473\n",
      "Epoch 65/200\n",
      "1600/1600 [==============================] - 118s - loss: 2.9702 - acc: 0.3350 - val_loss: 2.4464 - val_acc: 0.4479\n",
      "Epoch 66/200\n",
      "1600/1600 [==============================] - 117s - loss: 2.9906 - acc: 0.3307 - val_loss: 2.4619 - val_acc: 0.4562\n",
      "Epoch 67/200\n",
      "1600/1600 [==============================] - 116s - loss: 2.9647 - acc: 0.3396 - val_loss: 2.4336 - val_acc: 0.4532\n",
      "Epoch 68/200\n",
      "1600/1600 [==============================] - 114s - loss: 2.9386 - acc: 0.3391 - val_loss: 2.4784 - val_acc: 0.4429\n",
      "Epoch 69/200\n",
      "1600/1600 [==============================] - 117s - loss: 2.9507 - acc: 0.3363 - val_loss: 2.4255 - val_acc: 0.4631\n",
      "Epoch 70/200\n",
      "1600/1600 [==============================] - 117s - loss: 2.9222 - acc: 0.3463 - val_loss: 2.4193 - val_acc: 0.4582\n",
      "Epoch 71/200\n",
      "1600/1600 [==============================] - 117s - loss: 2.9634 - acc: 0.3362 - val_loss: 2.4000 - val_acc: 0.4647\n",
      "Epoch 72/200\n",
      "1600/1600 [==============================] - 116s - loss: 2.9328 - acc: 0.3454 - val_loss: 2.4241 - val_acc: 0.4650\n",
      "Epoch 73/200\n",
      "1600/1600 [==============================] - 115s - loss: 2.9529 - acc: 0.3398 - val_loss: 2.3989 - val_acc: 0.4722\n",
      "Epoch 74/200\n",
      "1600/1600 [==============================] - 115s - loss: 2.9294 - acc: 0.3430 - val_loss: 2.4910 - val_acc: 0.4388\n",
      "Epoch 75/200\n",
      "1600/1600 [==============================] - 114s - loss: 2.9019 - acc: 0.3480 - val_loss: 2.4211 - val_acc: 0.4657\n",
      "Epoch 76/200\n",
      "1600/1600 [==============================] - 115s - loss: 2.9315 - acc: 0.3434 - val_loss: 2.3750 - val_acc: 0.4773\n",
      "Epoch 77/200\n",
      "1600/1600 [==============================] - 115s - loss: 2.9155 - acc: 0.3457 - val_loss: 2.4253 - val_acc: 0.4640\n",
      "Epoch 78/200\n",
      "1600/1600 [==============================] - 115s - loss: 2.9510 - acc: 0.3441 - val_loss: 2.4947 - val_acc: 0.4505\n",
      "Epoch 79/200\n",
      "1600/1600 [==============================] - 115s - loss: 2.8888 - acc: 0.3539 - val_loss: 2.4044 - val_acc: 0.4640\n",
      "Epoch 80/200\n",
      "1600/1600 [==============================] - 114s - loss: 2.9511 - acc: 0.3418 - val_loss: 2.4284 - val_acc: 0.4580\n",
      "Epoch 81/200\n",
      "1599/1600 [============================>.] - ETA: 0s - loss: 2.9435 - acc: 0.3406- ETA: 0s - loss: 2.9434 - acc: 0.340"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = 1600,\n",
    "        epochs = epochs,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('second_try.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
